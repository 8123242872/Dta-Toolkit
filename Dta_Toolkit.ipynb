{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Toolkit"
      ],
      "metadata": {
        "id": "mtbvTgTIO1BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.What is NumPy, and why is it widely used in Python?\n",
        "\"\"\"\n",
        " NumPy (short for Numerical Python) is a powerful open-source library in Python used primarily for numerical computing. It's widely used in data science, machine learning, scientific computing, and engineering due to its efficiency and versatility.\n",
        " At its core, NumPy provides:\n",
        "\n",
        "ndarray: A powerful N-dimensional array object (like lists, but faster and with more features).\n",
        "\n",
        "Mathematical functions: Tools for operations on arrays (element-wise and matrix-level).\n",
        "\n",
        "Linear algebra tools: Matrix multiplication, decomposition, etc.\n",
        "\n",
        "Random number generation: For simulations and modeling.\n",
        "\n",
        "Broadcasting: Efficient handling of operations between arrays of different shapes.\n",
        "⚡ Why is it widely used?\n",
        "Speed: NumPy is much faster than native Python lists due to:\n",
        "\n",
        "Written in C under the hood\n",
        "\n",
        "Vectorized operations (no for-loops needed)\n",
        "\n",
        "Memory efficiency: Arrays are stored in contiguous memory blocks, reducing overhead.\n",
        "\n",
        "Foundation for other libraries: Libraries like Pandas, SciPy, TensorFlow, and scikit-learn rely on NumPy arrays.\n",
        "\n",
        "Powerful functionality: Includes a wide range of functions for statistics, algebra, FFTs, etc.\n",
        "\n",
        "Ease of use: It integrates well with other tools and simplifies data manipulation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3TxTRWhIO5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.How does broadcasting work in NumPy?\n",
        "\"\"\"\n",
        " Broadcasting in NumPy is a powerful concept that allows arrays of different shapes to be used together in arithmetic operations without explicitly copying data. It's like NumPy \"stretches\" smaller arrays so they match the shape of the larger one—without actually changing their data.\n",
        " When you perform an operation (like addition, subtraction, etc.) between two arrays of different shapes, NumPy tries to \"broadcast\" the smaller array across the larger one so their shapes are compatible.\n",
        "\n",
        "✅ Rules of Broadcasting:\n",
        "Compare shapes from right to left.\n",
        "\n",
        "Two dimensions are compatible if:\n",
        "\n",
        "They are equal, or\n",
        "\n",
        "One of them is 1\n",
        "\n",
        "If all dimensions are compatible, NumPy broadcasts the smaller array to match the shape of the larger one.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l3nuc7H2PfYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.What is a Pandas DataFrame?\n",
        "\"\"\"\n",
        " A Pandas DataFrame is a powerful two-dimensional labeled data structure in Python, resembling a spreadsheet or SQL table. It's a fundamental building block for data manipulation and analysis in Pandas.\n",
        " Key Features:\n",
        "\n",
        "Rows and Columns: Data is organized into rows and columns, similar to a spreadsheet.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a3eQ4xX6P703"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.Explain the use of the groupby() method in Pandas.\n",
        "\"\"\"\n",
        " The groupby() method in Pandas is a powerful tool for splitting, applying, and combining data based on specific criteria. It allows you to group rows in a DataFrame based on one or more columns and perform operations on each group independently.\n",
        " Here's a breakdown of how groupby() works:\n",
        "\n",
        "Splitting: The DataFrame is divided into groups based on the specified column(s).\n",
        "\n",
        "Applying: A function (aggregation, transformation, or filtering) is applied to each group independently.\n",
        "\n",
        "Combining: The results of the function are combined into a new DataFrame.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nxJpYKCeQKHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Why is Seaborn preferred for statistical visualizations?\n",
        "\"\"\"\n",
        " Seaborn is a powerful Python library built on top of Matplotlib that simplifies creating aesthetically pleasing and informative statistical visualizations. It's particularly preferred for statistical visualizations due to its:\n",
        "\n",
        "High-level interface: Seaborn provides a high-level interface for creating complex visualizations with minimal code. You can easily create histograms, scatter plots, box plots, heatmaps, and more with just a few lines of code.\n",
        "\n",
        "Predefined themes and styles: Seaborn offers a variety of predefined themes and styles that make your visualizations look professional and visually appealing. You can easily customize these themes to match your branding or preferences.\n",
        "\n",
        "Statistical insights: Seaborn is designed to help you explore and understand relationships within your data. It provides functions for visualizing distributions, correlations, and trends, making it ideal for exploratory data analysis.\n",
        "\n",
        "Integration with Pandas: Seaborn seamlessly integrates with Pandas DataFrames, allowing you to visualize data directly from your data structures.\n",
        "\n",
        "Extensibility: Seaborn is highly extensible, allowing you to create custom visualizations and add your own functionalities.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pDRNHn8CQVqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.What are the differences between NumPy arrays and Python lists?\n",
        "\"\"\"\n",
        " NumPy arrays and Python lists are both used to store collections of data in Python, but they have significant differences in terms of functionality, performance, and usage. Here's a breakdown of the key differences:\n",
        "\n",
        "Functionality:\n",
        "\n",
        "NumPy arrays offer a wider range of mathematical operations and functions compared to Python lists. NumPy provides functions for element-wise operations, matrix operations, linear algebra, statistical calculations, and more. Python lists, on the other hand, have limited mathematical capabilities.\n",
        "\n",
        "Performance:\n",
        "\n",
        "NumPy arrays are significantly faster than Python lists for numerical computations. This is because NumPy arrays are implemented in C, which is a low level programming language, while Python lists are implemented in Python itself. NumPy arrays also store data in contiguous memory blocks, which improves access times.\n",
        "\n",
        "Memory usage:\n",
        "\n",
        "NumPy arrays are more memory efficient than Python lists. This is because NumPy arrays store data in a single contiguous block of memory, while Python lists store pointers  to individual elements in separate memory locations.\n",
        "\n",
        "Data types:\n",
        "\n",
        "NumPy arrays can store data of a single type (e.g., integers, floats), while Python lists can store data of different types (e.g., integers, strings, lists). This makes NumPy arrays more suitable for numerical computations where all elements are of the same type.\n",
        "\n",
        "Flexibility:\n",
        "\n",
        "Python lists are more flexible than NumPy arrays. You can easily add, remove, and modify elements in Python lists. NumPy arrays, on the other hand, have a fixed size and cannot be resized after creation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SjtOBQ7OQe5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.What is a heatmap, and when should it be used?\n",
        "\"\"\"\n",
        " A heatmap is a graphical representation of data where values are represented by colors. It's particularly useful for visualizing relationships and patterns in large datasets, especially when dealing with matrices or tables.\n",
        " Here's a breakdown of when to use heatmaps:\n",
        "\n",
        "Correlation matrices: Heatmaps are commonly used to visualize correlation matrices, which show the relationships between different variables in a dataset. Each cell in the heatmap represents the correlation coefficient between two variables, with darker colors indicating stronger correlations.\n",
        "\n",
        "Confusion matrices: Heatmaps are also used to visualize confusion matrices, which show the performance of a classification model by comparing predicted labels with actual labels. Each cell in the heatmap represents the number of instances classified into a particular category.\n",
        "\n",
        "Heatmaps are a powerful tool for visualizing complex data relationships and patterns. By using different colors to represent different values, heatmaps can help you quickly identify trends, outliers, and anomalies in your data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h5RexzF6QvVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.What does the term “vectorized operation” mean in NumPy?\n",
        "\"\"\"\n",
        " The term \"vectorized operation\" in NumPy refers to performing operations on entire arrays or subsets of arrays without explicitly writing loops. This means you can apply mathematical functions or operations to each element of an array simultaneously, leading to faster and more concise code.\n",
        " Here's a breakdown of how vectorized operations work in NumPy:\n",
        " NumPy provides a wide range of mathematical functions that operate on arrays element-wise. For example, you can add, subtract, multiply, divide, take the square root, exponentiate, and perform other mathematical operations on entire arrays.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ekg16J_FQ7Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.How does Matplotlib differ from Plotly?\n",
        "\"\"\"\n",
        " Matplotlib and Plotly are both popular Python libraries for creating visualizations, but they have distinct differences in terms of functionality, interactivity, and use cases. Here's a breakdown of the key differences between Matplotlib and Plotly:\n",
        "\n",
        "Functionality:\n",
        "\n",
        "Matplotlib: Matplotlib is a comprehensive plotting library that provides a wide range of plot types, customization options, and export capabilities. It's suitable for creating static visualizations for publications, reports, and presentations.\n",
        "\n",
        "Plotly: Plotly is a more interactive plotting library that allows you to create interactive visualizations with features like zooming, panning, and tooltips. It's ideal for creating dashboards, web applications, and exploratory data analysis.\n",
        "\n",
        "Interactivity:\n",
        "\n",
        "Matplotlib: Matplotlib visualizations are generally static and do not support interactivity. You can only interact with the plot by zooming or panning using the mouse. Plotly: Plotly visualizations are highly interactive, allowing users to zoom, pan, select data points, and hover over data to see additional information.\n",
        "\n",
        "Use cases:\n",
        "\n",
        "Matplotlib: Matplotlib is suitable for creating static visualizations for publications, reports, and presentations. It's also commonly used for exploratory data analysis\n",
        "Plotly: Plotly is ideal for creating interactive visualizations for dashboards, web applications, and exploratory data analysis. It's particularly useful for visualizing large datasets and complex relationships.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aRqq-XOaRPWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.What is the significance of hierarchical indexing in Pandas?\n",
        "\"\"\"\n",
        " Hierarchical indexing, also known as multi-level indexing, is a powerful feature in Pandas that allows you to create multi-dimensional indexes for DataFrames. This means you can have multiple levels of indexing, each representing a different dimension of your data.\n",
        " Here's the significance of hierarchical indexing in Pandas:\n",
        "\n",
        "Improved data organization: Hierarchical indexing allows you to organize your data in a more intuitive and hierarchical manner. You can group related data together and easily navigate through different levels of indexing.\n",
        "\n",
        "Efficient data retrieval: Hierarchical indexing enables efficient data retrieval by allowing you to select subsets of data based on multiple criteria. You can use tuples to specify multiple index levels when selecting data.\n",
        "\n",
        "Flexible data manipulation: Hierarchical indexing provides flexibility in data manipulation tasks such as reshaping, pivoting, and aggregating data. You can perform operations on specific levels of indexing without affecting other levels.\n",
        "\n",
        "Integration with other Pandas features: Hierarchical indexing seamlessly integrates with other Pandas features such as merging, joining, and reshaping data. You can use hierarchical indexing to align data from different sources and perform complex data transformations.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sPEk3u-wR25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.What is the role of Seaborn’s pairplot() function?\n",
        "\"\"\"\n",
        " Seaborn's pairplot() function is a powerful tool for visualizing relationships between multiple variables in a dataset. It creates a grid of scatter plots and histograms, allowing you to explore pairwise relationships and distributions simultaneously.\n",
        " Here's a breakdown of the role of pairplot() in Seaborn:\n",
        "\n",
        "Pairwise scatter plots and histograms: pairplot() generates scatter plots for each pair of variables in the dataset, showing the relationship between them. It also creates histograms along the diagonal, displaying the distribution of each variable individually.\n",
        "\n",
        "Easy exploration of relationships: pairplot() provides a convenient way to explore relationships between multiple variables without having to create individual plots for each pair. You can quickly identify patterns, trends, and correlations in your data.\n",
        "\n",
        "Visualization of distributions: The histograms along the diagonal of the pairplot() allow you to visualize the distribution of each variable individually. This helps you understand the shape, spread, and central tendency of each variable.\n",
        "\n",
        "Customization options: pairplot() offers various customization options, such as specifying the color palette, plot style, and axis labels. You can tailor the plot to match your preferences and improve readability.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WfWKAMxWSLan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12.What is the purpose of the describe() function in Pandas?\n",
        "\"\"\"\n",
        " The describe() function in Pandas is a powerful tool for generating descriptive statistics of a DataFrame or Series. It provides a concise summary of the central tendency, dispersion, and shape of the data distribution.\n",
        " Here's a breakdown of the purpose of describe() in Pandas:\n",
        "\n",
        "Summary statistics: describe() calculates various summary statistics for each column in the DataFrame or Series, including count, mean, standard deviation, minimum, maximum, and quartiles. These statistics provide insights into the overall characteristics of the data.\n",
        "\n",
        "Identification of outliers: describe() can help identify outliers in the data by examining the minimum and maximum values. Outliers are data points that deviate significantly from the rest of the data and may indicate errors or anomalies.\n",
        "\n",
        "Exploratory data analysis: describe() is commonly used in exploratory data analysis (EDA) to quickly understand the distribution and properties of the data. It helps analysts identify patterns, trends, and potential issues in the data before performing further analysis or modeling.\n",
        "\n",
        "Data cleaning and preprocessing: describe() can be used to identify missing values, inconsistencies, or errors in the data. This information can guide data cleaning and preprocessing steps to ensure the quality and reliability of the data for analysis.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JPGuqVnOSVRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.Why is handling missing data important in Pandas?\n",
        "\"\"\"\n",
        " Handling missing data is crucial in Pandas because missing values can significantly impact the accuracy and reliability of your data analysis. Missing values can arise due to various reasons, such as data entry errors, sensor malfunctions, or incomplete surveys.\n",
        " Here's why handling missing data is important in Pandas:\n",
        " Impact on analysis results: Missing values can lead to biased or inaccurate analysis results. For example, if you calculate the mean of a column with missing values, the mean will be skewed towards the non-missing values. This can lead to incorrect conclusions and decisions based on the analysis.\n",
        "\n",
        "Impact on analysis results: Missing values can lead to biased or inaccurate analysis results. For example, if you calculate the mean of a column with missing values, the mean will be skewed towards the non-missing values. This can lead to incorrect conclusions and decisions based on the analysis.\n",
        "\n",
        "Impact on model performance: Missing values can also impact the performance of machine learning models. Many machine learning algorithms cannot handle missing values, and models trained on data with missing values may produce inaccurate predictions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qPM4Dt0wSqO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.What are the benefits of using Plotly for data visualization?\n",
        "\"\"\"\n",
        " Plotly is a powerful Python library for creating interactive and visually appealing data visualizations. It offers several benefits that make it a popular choice for data visualization tasks:\n",
        "\n",
        "Interactive visualizations: Plotly visualizations are highly interactive, allowing users to zoom, pan, select data points, and hover over data to see additional information. This interactivity enhances user engagement and exploration of the data.\n",
        "\n",
        "Wide range of plot types: Plotly supports a wide range of plot types, including line plots, scatter plots, bar plots, histograms, box plots, heatmaps, and more. This versatility allows you to create visualizations suitable for various types of data and analysis tasks\n",
        " Customization options: Plotly provides extensive customization options for plot appearance, including colors, fonts, axes labels, legends, and annotations. You can tailor the visualization to match your preferences and improve readability.\n",
        "\n",
        "Integration with other tools: Plotly seamlessly integrates with other Python libraries and tools, such as Pandas, NumPy, and SciPy. You can easily create visualizations directly from Pandas DataFrames and use Plotly alongside other data analysis and visualization libraries.\n",
        "\n",
        "Export capabilities: Plotly visualizations can be exported to various formats, including PNG, JPEG, SVG, and PDF. This allows you to save and share your visualizations with others.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "n7WZ3Iz7TEPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15.How does NumPy handle multidimensional arrays?\n",
        "\"\"\"\n",
        " NumPy handles multidimensional arrays using its powerful ndarray object (short for N-dimensional array). These arrays can have any number of dimensions, and NumPy provides intuitive and fast tools to manipulate them.\n",
        " What is an ndarray?\n",
        "A NumPy array looks and behaves like a regular list or list of lists in Python—but it’s:\n",
        "\n",
        "More compact in memory\n",
        "\n",
        "Faster to compute\n",
        "\n",
        "Richer in features\n",
        "\n",
        "Shape and Dimensions\n",
        ".shape → returns a tuple with the size in each dimension\n",
        "\n",
        ".ndim → tells you the number of dimensions\n",
        "\n",
        ".size → total number of elements\n",
        "\n",
        ".dtype → data type of elements\n",
        "\n",
        " Indexing and Slicing\n",
        "Just like lists, but extended for more dimensions\n",
        "\n",
        "Reshaping and Transposing\n",
        "NumPy makes it super easy to reshape and rearrange\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v78RuWQmTUST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16.What is the role of Bokeh in data visualization?\n",
        "\"\"\"\n",
        " Bokeh is a powerful Python library for creating interactive and visually appealing data visualizations in web browsers. It offers several key roles in data visualization:\n",
        "\n",
        "Interactive visualizations: Bokeh enables the creation of interactive visualizations that allow users to explore and manipulate data dynamically. Users can zoom, pan, select data points, and hover over data to see\n",
        "  additional information. This interactivity enhances user engagement and exploration of the data.\n",
        "\n",
        "Web-based deployment: Bokeh visualizations can be easily deployed to web servers or hosted on platforms like Heroku, allowing users to access and interact with visualizations from anywhere with a web browser. This makes it ideal for sharing visualizations with colleagues, clients.\n",
        "\n",
        "Seamless Integration with Python: You can combine Bokeh with other libraries like Pandas, NumPy, and SciPy, making it easy to visualize data from a Python environment.\n",
        "\n",
        "Customizable: Bokeh provides a flexible and detailed API that allows for deep customization of the visual appearance, layout, and interactivity.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lj6dfU2NULNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Explain the difference between apply() and map() in Pandas.\n",
        "\"\"\"\n",
        " apply() and map() are two powerful functions in Pandas used for applying functions to elements of a DataFrame or Series. While they share some similarities, they differ in their behavior and use cases. Here's a breakdown of the differences between apply() and map():\n",
        "\n",
        "Functionality:\n",
        "\n",
        "apply(): apply() is a versatile function that can apply a function to elements of a DataFrame or Series along a specified axis (rows or columns). It can handle functions that operate on individual elements, rows, or columns.\n",
        "\n",
        "map(): map() is specifically designed for applying functions to elements of a Series. It applies the function element-wise and returns a new Series with the transformed values.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Yx2OPHMMVMWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18.What are some advanced features of NumPy?\n",
        "\"\"\"\n",
        " NumPy offers a wide range of advanced features that make it a powerful tool for numerical computing in Python. Here are some of the key advanced features of NumPy:\n",
        "\n",
        "Vectorized operations: NumPy allows you to perform mathematical operations on entire arrays or subsets of arrays without explicitly writing loops. This leads to faster and more concise code. For example, you can add, subtract, multiply, divide, take the square root, exponentiate, and perform other mathematical operations on entire arrays.\n",
        "\n",
        "Broadcasting: NumPy's broadcasting feature enables arrays of different shapes to be used together in arithmetic operations without explicitly copying data. This allows for efficient and concise code when working with arrays of different shapes.\n",
        "\n",
        "Linear algebra functions: NumPy provides a comprehensive set of functions for linear algebra operations, such as matrix multiplication, matrix inversion, eigenvalue decomposition, and singular value decomposition. These functions are optimized for performance and can handle large matrices efficiently.\n",
        "\n",
        "Random number generation: NumPy includes functions for generating random numbers from various distributions, such as uniform, normal, binomial, and Poisson distributions. These functions are useful for simulations, modeling, and statistical analysis.\n",
        "\n",
        "Fast Fourier transforms: NumPy provides functions for computing fast Fourier transforms (FFTs), which are used for analyzing signals and images. FFTs are widely used in signal processing and image processing applications.\n",
        "\n",
        "Sparse matrices: NumPy supports sparse matrices, which are matrices with a large number of zero elements. Sparse matrices are stored efficiently using specialized data structures, making them suitable for handling large and sparse datasets.\n",
        "\n",
        "Integration with other libraries: NumPy seamlessly integrates with other Python libraries, such as SciPy, Pandas, and scikit-learn. This allows you to leverage the capabilities of NumPy alongside other libraries for data analysis, machine learning, and scientific computing.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-uLfnCTAVVVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. How does Pandas simplify time series analysis?\n",
        "\"\"\"\n",
        " Pandas simplifies time series analysis by providing powerful tools and functionalities specifically designed for working with time series data. Here's how Pandas simplifies time series analysis:\n",
        "\n",
        "Time series data structures: Pandas introduces specialized data structures, such as Timestamp, DatetimeIndex, and PeriodIndex, to represent time series data. These data structures handle time-related operations efficiently and provide intuitive interfaces for working with time series data.\n",
        "\n",
        "Time series indexing: Pandas allows you to use timestamps or periods as indexes for time series data. This enables easy selection, slicing, and aggregation of data based on time intervals. For example, you can select data for a specific month, quarter, or year using time-based indexing.\n",
        "\n",
        "Resampling and frequency conversion: Pandas provides functions for resampling time series data to different frequencies, such as converting daily data to monthly or weekly data. This allows you to aggregate or interpolate data to different time intervals, facilitating analysis and visualization.\n",
        "\n",
        "Time series operations: Pandas offers a wide range of functions for performing time series operations, such as rolling calculations, moving averages, exponential smoothing, and differencing. These operations help you extract meaningful insights and patterns from time series data.\n",
        "\n",
        "Integration with visualization libraries: Pandas seamlessly integrates with visualization libraries like Matplotlib and Seaborn, allowing you to create time series plots, line charts, scatter plots, and other visualizations easily. This enables you to explore and communicate insights from time series data effectively.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rXM4OumpVlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20.What is the role of a pivot table in Pandas?\n",
        "\"\"\"\n",
        " A pivot table in Pandas is a powerful tool for summarizing and reshaping data in a DataFrame. It allows you to rearrange the data in a way that makes it easier to analyze and understand.\n",
        " Here's a breakdown of the role of a pivot table in Pandas:\n",
        "\n",
        "Summarization: Pivot tables provide a concise summary of data by aggregating values based on specified rows, columns, and values. This allows you to quickly identify patterns, trends, and relationships in your data.\n",
        "\n",
        "Reshaping: Pivot tables can reshape data from long format to wide format or vice versa. This enables you to transform data structures to facilitate analysis and visualization. For example, you can convert a DataFrame with multiple rows representing different categories into a pivot table with categories as columns and values as rows.\n",
        "\n",
        "Filtering: Pivot tables allow you to filter data based on specific criteria. You can select rows or columns based on their values or conditions, enabling you to focus on relevant subsets of data for analysis.\n",
        "\n",
        "Aggregation: Pivot tables support various aggregation functions, such as sum, mean, count, min, max, and more. These functions allow you to calculate summary statistics for different groups of data, providing insights into the distribution and characteristics of your data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v3sc1N0SV35D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21.Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "\"\"\"\n",
        " NumPy's array slicing is faster than Python's list slicing due to several factors:\n",
        "\n",
        "Contiguous memory allocation: NumPy arrays store data in contiguous memory blocks, which means that elements of an array are stored next to each other in memory. This allows for efficient access to elements during slicing, as the memory locations of the elements are known in advance. In contrast, Python lists store elements in separate memory locations, which can lead to slower access during slicing.\n",
        "\n",
        "Optimized algorithms: NumPy implements optimized algorithms for slicing arrays, which are tailored to the characteristics of NumPy arrays. These algorithms take advantage of the contiguous memory allocation and other optimizations to perform slicing efficiently.\n",
        "\n",
        "Vectorized operations: NumPy supports vectorized operations, which allow you to perform operations on entire arrays or subsets of arrays without explicitly writing loops. This eliminates the need for iterating over individual elements during slicing, leading to faster execution.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q6W7PE0KWIy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22.What are some common use cases for Seaborn?\n",
        "\"\"\"\n",
        " Seaborn is a powerful Python library for creating aesthetically pleasing and informative statistical visualizations. It offers several common use cases that make it valuable for data analysis and exploration:\n",
        "\n",
        "Exploratory data analysis (EDA): Seaborn is widely used for exploratory data analysis, where analysts explore and understand the characteristics and relationships within a dataset. It provides functions for visualizing distributions, correlations, trends, and patterns in the data, helping analysts uncover insights and identify potential issues.\n",
        "\n",
        "Data visualization for presentations and reports: Seaborn is commonly used to create visualizations for presentations, reports, and dashboards. Its aesthetically pleasing and customizable plots make it suitable for communicating insights and findings to stakeholders effectively.\n",
        "Statistical modeling and analysis: Seaborn integrates well with statistical modeling libraries like scikit-learn and statsmodels, allowing analysts to visualize the results of statistical models and assess their performance. It provides functions for visualizing regression lines, confidence intervals, and residuals, aiding in model interpretation and evaluation.\n",
        "Comparison and analysis of multiple datasets: Seaborn facilitates the comparison and analysis of multiple datasets by allowing analysts to create faceted plots, grouped plots, and stacked plots. This enables analysts to explore differences and similarities across different groups or categories within the data.\n",
        "Visualization of complex relationships: Seaborn provides functions for visualizing complex relationships between multiple variables, such as heatmaps, pair plots, and joint plots. These visualizations help analysts uncover patterns, clusters, and correlations in high-dimensional datasets.\n",
        "  Visualization of time series data: Seaborn supports the visualization of time series data, including line plots, scatter plots, and heatmaps. This enables analysts to explore trends, seasonality, and anomalies in time series data over time.\n",
        "  Visualization of categorical data: Seaborn provides functions for visualizing categorical data, such as bar plots, count plots, and box plots. These visualizations help analysts understand the distribution and relationships within categorical variables.\n",
        "  Visualization of geospatial data: Seaborn can be used to visualize geospatial data, such as maps and choropleth maps, by integrating with libraries like Folium and GeoPandas. This enables analysts to explore spatial patterns and relationships in geographic datasets.\n",
        "  Visualization of network data: Seaborn can be used to visualize network data, such as network graphs and Sankey diagrams, by integrating with libraries like NetworkX and Pyvis. This enables analysts to explore relationships and interactions within complex networks.\n",
        "  Visualization of hierarchical data: Seaborn provides functions for visualizing hierarchical data, such as dendrograms and heatmaps, by integrating with libraries like SciPy and Seaborn. This enables analysts to explore hierarchical relationships and clusters within hierarchical datasets.\n",
        "  Visualization of multidimensional data: Seaborn provides functions for visualizing multidimensional data, such as parallel coordinates plots and scatter matrix plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore relationships and patterns in high-dimensional datasets.\n",
        "  Visualization of interactive data: Seaborn can be used to create interactive visualizations, such as dashboards and web applications, by integrating with libraries like Plotly and Dash. This enables analysts to explore and manipulate data dynamically in real-time.\n",
        "  Visualization of machine learning models: Seaborn provides functions for visualizing machine learning models, such as decision trees, random forests, and neural networks, by integrating with libraries like scikit-learn and TensorFlow. This enables analysts to interpret and evaluate the performance of machine learning models.\n",
        "  Visualization of natural language processing (NLP) data: Seaborn can be used to visualize NLP data, such as word clouds and topic models, by integrating with libraries like NLTK and Gensim. This enables analysts to explore patterns and themes within textual data.\n",
        "  Visualization of audio and video data: Seaborn can be used to visualize audio and video data, such as spectrograms and time-frequency plots, by integrating with libraries like Librosa and OpenCV. This enables analysts to explore patterns and features within audio and video data.\n",
        "  Visualization of sensor data: Seaborn can be used to visualize sensor data, such as time series plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within sensor data collected from IoT devices and sensors.\n",
        "  Visualization of financial data: Seaborn can be used to visualize financial data, such as candlestick charts and line plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within financial markets and investments.\n",
        "  Visualization of sports data: Seaborn can be used to visualize sports data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within sports analytics and performance metrics.\n",
        "  Visualization of healthcare data: Seaborn can be used to visualize healthcare data, such as line plots and scatter plots, by integrating with libraries like Pandas and NumPy . This enables analysts to explore patterns and trends within healthcare datasets, such as patient demographics, medical records, and treatment outcomes.\n",
        "  Visualization of social media data: Seaborn can be used to visualize social media data, such as word clouds and network graphs, by integrating with libraries like NLTK and NetworkX. This enables analysts to explore patterns and trends within social media conversations and networks.\n",
        "  Visualization of environmental data: Seaborn can be used to visualize environmental data, such as maps and choropleth maps, by integrating with libraries like Folium and GeoPandas. This enables analysts to explore patterns and trends within environmental datasets, such as climate change, pollution, and biodiversity.\n",
        "  Visualization of educational data: Seaborn can be used to visualize educational data, such as bar plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within educational datasets, such as student performance, attendance, and engagement.\n",
        "  Visualization of marketing data: Seaborn can be used to visualize marketing data, such as funnel charts and conversion rate charts, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within marketing campaigns and customer journeys.\n",
        "  Visualization of customer data: Seaborn can be used to visualize customer data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within customer behavior, preferences, and interactions.\n",
        "  Visualization of supply chain data: Seaborn can be used to visualize supply chain data, such as network graphs and Sankey diagrams, by integrating with libraries like NetworkX and Pyvis. This enables analysts to explore patterns and trends within supply chain networks and logistics operations.\n",
        "  Visualization of manufacturing data: Seaborn can be used to visualize manufacturing data, such as time series plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within manufacturing processes and quality control metrics.\n",
        "  Visualization of retail data: Seaborn can be used to visualize retail data, such as bar plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within retail sales, inventory, and customer behavior.\n",
        "  Visualization of transportation data: Seaborn can be used to visualize transportation data, such as maps and choropleth maps, by integrating with libraries like Folium and GeoPandas. This enables analysts to explore patterns and trends within transportation networks and logistics operations.\n",
        "  Visualization of energy data: Seaborn can be used to visualize energy data, such as time series plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within energy consumption, production, and renewable energy sources.\n",
        "  Visualization of agriculture data: Seaborn can be used to visualize agriculture data, such as maps and choropleth maps, by integrating with libraries like Folium and GeoPandas. This enables analysts to explore patterns and trends within agricultural datasets, such as crop yields, soil conditions, and irrigation practices.\n",
        "  Visualization of weather data: Seaborn can be used to visualize weather data, such as time series plots and scatter plots, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within weather datasets, such as temperature, precipitation, and wind speed.\n",
        "  Visualization of astronomy data: Seaborn can be used to visualize astronomy data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within astronomical datasets, such as celestial objects, observations, and discoveries.\n",
        "  Visualization of biology data: Seaborn can be used to visualize biology data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within biological datasets, such as gene expression, protein interactions, and evolutionary relationships.\n",
        "  Visualization of chemistry data: Seaborn can be used to visualize chemistry data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within chemical datasets, such as molecular structures, reactions, and properties.\n",
        "  Visualization of physics data: Seaborn can be used to visualize physics data such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within physical datasets, such as particle physics, quantum mechanics, and thermodynamics.\n",
        "  Visualization of mathematics data: Seaborn can be used to visualize mathematics data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within mathematical datasets, such as number theory, algebra, and calculus.\n",
        "  Visualization of computer science data: Seaborn can be used to visualize computer science data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within computer science datasets, such as algorithms, data structures, and programming languages.\n",
        "  Visualization of engineering data: Seaborn can be used to visualize engineering data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within engineering datasets, such as mechanical engineering, electrical engineering, and civil engineering.\n",
        "  Visualization of business data: Seaborn can be used to visualize business data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within business datasets, such as sales, marketing, and finance.\n",
        "  Visualization of social science data: Seaborn can be used to visualize social science data, such as scatter plots and heatmaps, by integrating with libraries like Pandas and NumPy. This enables analysts to explore patterns and trends within social science datasets, such as sociology, psychology, and anthropology.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "g-YvAvj8Wc4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "kQ6yS_kcY7aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "import numpy as np\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "row_sums = np.sum(arr, axis=1)\n",
        "print(row_sums)"
      ],
      "metadata": {
        "id": "7gAlR_mzY_n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Write a Pandas script to find the mean of a specific column in a DataFrame.\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data to create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [24, 27, 22, 32, 29],\n",
        "    'Salary': [50000, 60000, 55000, 80000, 75000]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the mean of a specific column (e.g., 'Age')\n",
        "mean_age = df['Age'].mean()\n",
        "\n",
        "print(\"Mean Age:\", mean_age)\n",
        "\n",
        "# Alternatively, you can find the mean of another column, like 'Salary'\n",
        "mean_salary = df['Salary'].mean()\n",
        "\n",
        "print(\"Mean Salary:\", mean_salary)\n"
      ],
      "metadata": {
        "id": "TINFY2ezX2cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Create a scatter plot using Matplotlib.\n",
        " import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for the scatter plot\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 20, 25, 30, 35]\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.scatter(x, y, color='blue', marker='o', label='Data points')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Simple Scatter Plot')\n",
        "plt.xlabel('X Values')\n",
        "plt.ylabel('Y Values')\n",
        "\n",
        "# Optional: Display the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zVX_WdgmWnOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "\n",
        " import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data to create a DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6],\n",
        "    'D': [5, 3, 4, 2, 1]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))  # Adjust the size of the plot\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-1uQwaV4aIqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Generate a bar plot using Plotly.\n",
        "import plotly.express as px\n",
        "\n",
        "# Sample data for the bar plot\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
        "values = [10, 20, 15, 25]\n",
        "fig = px.bar(x=categories, y=values, title='Simple Bar Plot', labels={'x': 'Categories', 'y': 'Values'})\n",
        "fig.show()\n",
        ""
      ],
      "metadata": {
        "id": "RE4c1W3maUUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Create a DataFrame and add a new column based on an existing column.\n",
        "\n",
        " import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [24, 27, 22, 32, 29],\n",
        "    'Salary': [50000, 60000, 55000, 80000, 75000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a new column 'Age Group' based on the 'Age' column\n",
        "df['Age Group'] = df['Age'].apply(lambda x: 'Young' if x < 30 else 'Adult')\n",
        "\n",
        "# Show the updated DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "GFtCkpEJaf-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.Write a program to perform element-wise multiplication of two NumPy arrays.\n",
        " import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4])\n",
        "array2 = np.array([5, 6, 7, 8])\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Print the result\n",
        "print(\"Element-wise multiplication result:\", result)\n"
      ],
      "metadata": {
        "id": "Xuhd3FuGasuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.Create a line plot with multiple lines using Matplotlib.\n",
        " import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for multiple lines\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [10, 20, 25, 30, 35]\n",
        "\n",
        "y2 = [5, 15, 20, 25, 30]\n",
        "\n",
        "# Create the line plot with multiple lines\n",
        "plt.plot(x, y1, label='Line 1', color='blue', linestyle='-', marker='o')\n",
        "plt.plot(x, y2, label='Line 2', color='red', linestyle='--', marker='s')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Multiple Line Plot')\n",
        "plt.xlabel('X Values') plt.ylabel('Y Values')\n",
        "\n",
        "# Optional: Display the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "BCAK3k6Sa0-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold.\n",
        " import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [24, 27, 22, 32, 29],\n",
        "    'Salary': [50000, 60000, 55000, 80000, 75000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set a threshold for the 'Salary' column\n",
        "salary_threshold = 60000\n",
        "\n",
        "# Filter rows where 'Salary' is greater than the threshold\n",
        "filtered_df = df[df['Salary'] > salary_threshold]\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "id": "OEEeenbybKAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.Create a histogram using Seaborn to visualize a distribution.\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "data = [24, 27, 22, 32, 29, 24, 28, 33, 25, 22, 24, 30, 32, 31, 29]\n",
        "\n",
        "# Create a histogram using Seaborn\n",
        "sns.histplot(data, kde=True, color='blue', bins=10)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Histogram with Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z0Y2PY4EbgSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.Perform matrix multiplication using NumPy.\n",
        " import numpy as np\n",
        "\n",
        "# Define two matrices (2D arrays)\n",
        "matrix1 = np.array([[1, 2], [3, 4]])\n",
        "matrix2 = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication using the @ operator\n",
        "result = matrix1 @ matrix2\n",
        "\n",
        "# Alternatively, you can use np.dot() for matrix multiplication\n",
        "# result = np.dot(matrix1, matrix2)\n",
        "\n",
        "# Print the result\n",
        "print(\"Result of matrix multiplication:\\n\", result)\n"
      ],
      "metadata": {
        "id": "i3ZrpRGhbyXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Use Pandas to load a CSV file and display its first 5 rows.\n",
        "  import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('path_to_your_file.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "sX7p1xXtcNvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.Create a 3D scatter plot using Plotly.\n",
        " import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'x': [1, 2, 3, 4, 5],\n",
        "    'y': [5, 6, 7, 8, 9],\n",
        "    'z': [10, 11, 12, 13, 14],\n",
        "    'color': ['red', 'blue', 'green', 'orange', 'purple']  # Optional color attribute\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = px.scatter_3d(df, x='x', y='y', z='z', color='color', title='3D Scatter Plot')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "IzVOMcAiccDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}